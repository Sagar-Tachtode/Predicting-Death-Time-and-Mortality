{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------- POC -----------\n",
    "# Phase 1 - Ensembling LSTM and RF to predict in-hospital mortality\n",
    "\n",
    "In the POC stage, we have explored the feasibility of using LSTM to handle time series data of some high temporal data and ensembled with random forest classifier trained on other features to predict in-hospital mortality in Phase 1. This notebook presents some of the findings based on 6-hour ICU data.\n",
    "\n",
    "* Part 1. LSTM for time series data\n",
    "* Part 2. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from utils import connect_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1. LSTM for time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the following types of features. We will train one LSTM model for each feature in timeseries_features  separately in Part 1. Then we will combine the predict proba resulted from the LSTM models with other features in catergorial_feature and aggregated_features, and train a random forest classifier to predict the in-hospital mortality in Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features\n",
    "timeseries_features = ['heartrate', 'sysbp', 'diasbp', 'meanbp', 'resprate', 'spo2']\n",
    "categorical_features = ['gender', 'ethnicity', 'admission_type']\n",
    "aggregated_features = ['age', 'icustay_num',\n",
    "                       'tempc_mean', 'glucose_mean', \n",
    "                       'tempc_min',  'glucose_min',\n",
    "                       'tempc_max',  'glucose_max', \n",
    "                       'gcs_mean', 'gcsmotor_mean', 'gcsverbal_mean', 'gcseyes_mean', 'endotrachflag_mean',\n",
    "                       'gcs_min', 'gcsmotor_min', 'gcsverbal_min', 'gcseyes_min', 'endotrachflag_min', \n",
    "                       'gcs_max', 'gcsmotor_max', 'gcsverbal_max', 'gcseyes_max', 'endotrachflag_max', \n",
    "                       'baseexcess_mean', 'carboxyhemoglobin_mean', 'methemoglobin_mean', \n",
    "                       'po2_mean', 'pco2_mean', 'ph_mean', 'pao2fio2ratio_mean', 'totalco2_mean', \n",
    "                       'aniongap_mean', 'albumin_mean', 'bands_mean', 'bicarbonate_mean', \n",
    "                       'bilirubin_mean', 'calcium_mean', 'creatinine_mean', 'chloride_mean', \n",
    "                       'hematocrit_mean', 'hemoglobin_mean', 'lactate_mean', 'platelet_mean', \n",
    "                       'potassium_mean', 'ptt_mean', 'inr_mean', 'sodium_mean', 'bun_mean', 'wbc_mean',\n",
    "                       'baseexcess_min', 'carboxyhemoglobin_min', 'methemoglobin_min',\n",
    "                       'po2_min', 'pco2_min', 'ph_min', 'pao2fio2ratio_min', 'totalco2_min',\n",
    "                       'aniongap_min', 'albumin_min', 'bands_min', 'bicarbonate_min',\n",
    "                       'bilirubin_min', 'calcium_min', 'creatinine_min', 'chloride_min',\n",
    "                       'hematocrit_min', 'hemoglobin_min', 'lactate_min', 'platelet_min',\n",
    "                       'potassium_min', 'ptt_min', 'inr_min', 'sodium_min', 'bun_min', 'wbc_min', \n",
    "                       'baseexcess_max', 'carboxyhemoglobin_max', 'methemoglobin_max', \n",
    "                       'po2_max', 'pco2_max', 'ph_max', 'pao2fio2ratio_max', 'totalco2_max',          \n",
    "                       'aniongap_max', 'albumin_max', 'bands_max', 'bicarbonate_max', \n",
    "                       'bilirubin_max', 'calcium_max', 'creatinine_max', 'chloride_max', \n",
    "                       'hematocrit_max', 'hemoglobin_max', 'lactate_max', 'platelet_max', \n",
    "                       'potassium_max', 'ptt_max', 'inr_max', 'sodium_max', 'bun_max', 'wbc_max', \n",
    "                       'urineoutput']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will prepare the time series data for fitting LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test-validation split: 31764 7941 9927\n",
      "heartrate (49632, 9)\n",
      "sysbp (49632, 9)\n",
      "diasbp (49632, 9)\n",
      "meanbp (49632, 9)\n",
      "resprate (49632, 9)\n",
      "spo2 (49632, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>93.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>125.5</td>\n",
       "      <td>122.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>114.666667</td>\n",
       "      <td>109.0</td>\n",
       "      <td>109.5</td>\n",
       "      <td>115.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200006</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>200007</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>93.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200009</td>\n",
       "      <td>0</td>\n",
       "      <td>94.8</td>\n",
       "      <td>105.5</td>\n",
       "      <td>101.0</td>\n",
       "      <td>97.666667</td>\n",
       "      <td>101.5</td>\n",
       "      <td>91.5</td>\n",
       "      <td>90.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    icustay_id  hospital_expire_flag      0      1      2           3      4  \\\n",
       "0       200001                     0  114.0  108.0  110.0  102.000000  108.0   \n",
       "7       200003                     0  125.5  122.0  117.0  114.666667  109.0   \n",
       "14      200006                     0   81.0   73.0   78.0   77.000000   80.0   \n",
       "21      200007                     0   87.0   83.0   85.0   85.000000  104.0   \n",
       "28      200009                     0   94.8  105.5  101.0   97.666667  101.5   \n",
       "\n",
       "        5       6  \n",
       "0   104.0   93.00  \n",
       "7   109.5  115.25  \n",
       "14   85.0   78.00  \n",
       "21   80.0   93.00  \n",
       "28   91.5   90.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load time series data\n",
    "query = '''\n",
    "        select icustay_id, hr, heartrate, sysbp, diasbp, meanbp, resprate, spo2, hospital_expire_flag\n",
    "        from mimiciii.mp_data\n",
    "        inner join mimiciii.mp_cohort\n",
    "        using (icustay_id)\n",
    "        where hr>=0 and hr<=6\n",
    "        order by icustay_id, hr\n",
    "        '''\n",
    "df = connect_db(query)\n",
    "\n",
    "# impute missing values of numerical features with median\n",
    "for col in timeseries_features:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "# split data into train, validation and test set\n",
    "id_train, id_test = train_test_split(df.icustay_id.unique(), test_size=0.2, random_state=0)\n",
    "id_train, id_val = train_test_split(id_train, test_size=0.2, random_state=0)\n",
    "id_train.sort()\n",
    "id_val.sort()\n",
    "id_test.sort()\n",
    "print('Train-test-validation split:', id_train.shape[0], id_val.shape[0], id_test.shape[0])\n",
    "\n",
    "# mortality label\n",
    "labels = df[['icustay_id', 'hospital_expire_flag']].drop_duplicates()\n",
    "\n",
    "# pivoting to construct 6-hour time series for each feature\n",
    "df_timeseries = {}\n",
    "for feature in timeseries_features :\n",
    "    df_tmp = df.pivot(index='icustay_id', columns='hr', values=feature)\n",
    "    df_tmp = labels.merge(df_tmp, left_on='icustay_id', right_index=True, how='inner')\n",
    "    df_tmp = df_tmp.fillna(0)\n",
    "    df_timeseries[feature] = df_tmp\n",
    "    print(feature, df_timeseries[feature].shape)\n",
    "\n",
    "df_timeseries['heartrate'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to train LSTM on the time series data. We define 2 methods to train LSTM and make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM for feature heartrate\n",
      "7941/7941 [==============================] - 0s 13us/step\n",
      "Accuracy on validation set =  0.882004785291525\n",
      "Training LSTM for feature sysbp\n",
      "7941/7941 [==============================] - 0s 16us/step\n",
      "Accuracy on validation set =  0.8813751416698149\n",
      "Training LSTM for feature diasbp\n",
      "7941/7941 [==============================] - 0s 21us/step\n",
      "Accuracy on validation set =  0.8809973554967888\n",
      "Training LSTM for feature meanbp\n",
      "7941/7941 [==============================] - 0s 23us/step\n",
      "Accuracy on validation set =  0.882004785291525\n",
      "Training LSTM for feature resprate\n",
      "7941/7941 [==============================] - 0s 27us/step\n",
      "Accuracy on validation set =  0.8806195693237627\n",
      "Training LSTM for feature spo2\n",
      "7941/7941 [==============================] - 0s 31us/step\n",
      "Accuracy on validation set =  0.8813751416698149\n"
     ]
    }
   ],
   "source": [
    " def train_lstm(df_train, df_val):\n",
    "    X_train = df_train.drop(columns=['icustay_id','hospital_expire_flag'])\n",
    "    y_train = df_train.hospital_expire_flag\n",
    "    X_val = df_val.drop(columns=['icustay_id','hospital_expire_flag'])\n",
    "    y_val = df_val.hospital_expire_flag\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_val = np.array(X_val)\n",
    "    \n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "    #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "    feature_dim = X_train.shape[2]\n",
    "    timesteps = X_train.shape[1]\n",
    "    \n",
    "    # build model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32,input_shape=(timesteps, feature_dim)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\",  metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=0)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    score = model.evaluate(X_val, y_val, batch_size=128) #return loss and metric value\n",
    "    print('Accuracy on validation set = ', score[1])\n",
    "            \n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_lstm(df, model):\n",
    "    X = df.drop(columns=['icustay_id','hospital_expire_flag'])\n",
    "    y = df.hospital_expire_flag\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "    y_pred_proba = model.predict(X)\n",
    "    return y_pred_proba\n",
    "\n",
    "\n",
    "# train one LSTM model for each feature separately \n",
    "models = {} \n",
    "for f in timeseries_features:\n",
    "    df_train = df_timeseries[f][df_timeseries[f].icustay_id.isin(id_train)]\n",
    "    df_val = df_timeseries[f][df_timeseries[f].icustay_id.isin(id_val)]\n",
    "    print('Training LSTM for feature', f)\n",
    "    models[f] = train_lstm(df_train, df_val)\n",
    "    \n",
    "    \n",
    "# predict for training set, validation set using trained LSTM \n",
    "df_ts_train = labels[labels.icustay_id.isin(id_train)].sort_values(by=['icustay_id'])\n",
    "df_ts_val = labels[labels.icustay_id.isin(id_val)].sort_values(by=['icustay_id'])\n",
    "\n",
    "for f in timeseries_features:\n",
    "    df_train = df_timeseries[f][df_timeseries[f].icustay_id.isin(id_train)].sort_values(by=['icustay_id'])\n",
    "    df_ts_train[f] = predict_lstm(df_train, models[feature])\n",
    "    df_val = df_timeseries[f][df_timeseries[f].icustay_id.isin(id_val)].sort_values(by=['icustay_id'])\n",
    "    df_ts_val[f] = predict_lstm(df_val, models[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2. RandomForestClassifier\n",
    "\n",
    "In this part, we will use the prediction proba resulted from the LSTM model in Part 1, and combine them with other aggregated/static features to train a ranom forest classifier. First, we define a method which comes handy for us to evaluate the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, y_pred_proba):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1score = f1_score(y_true, y_pred)   \n",
    "    print (\"Accuracy : {:.4f}\".format(acc))\n",
    "    print(\"AUC score : {:.4f}\".format(auc))\n",
    "    print(\"Precision : {:.4f}\".format(precision))\n",
    "    print(\"Recall : {:.4f}\".format(recall))\n",
    "    print(\"F1 score : {:.4f}\".format(f1score))\n",
    "    print(\"\\nClassification report : \\n\", classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion matrix : \\n\", confusion_matrix(y_true, y_pred))\n",
    "    return acc, auc, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8957\n",
      "AUC score : 0.8147\n",
      "Precision : 0.6911\n",
      "Recall : 0.2289\n",
      "F1 score : 0.3439\n",
      "\n",
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94      6993\n",
      "          1       0.69      0.23      0.34       948\n",
      "\n",
      "avg / total       0.88      0.90      0.87      7941\n",
      "\n",
      "\n",
      "Confusion matrix : \n",
      " [[6896   97]\n",
      " [ 731  217]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8957310162448054,\n",
       " 0.8147114112303986,\n",
       " 0.6910828025477707,\n",
       " 0.2289029535864979,\n",
       " 0.3438985736925515)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load aggregated/static data\n",
    "df_6hr = pd.read_csv('../data/mp_data_6hr.csv')\n",
    "\n",
    "# impute missing values of numerical features with median\n",
    "for col in aggregated_features:\n",
    "    df_6hr[col].fillna(df_6hr[col].median(), inplace=True)\n",
    "    \n",
    "# encoding categorical features\n",
    "le_gender = LabelEncoder()\n",
    "df_6hr['gender'] = le_gender.fit_transform(df_6hr.gender)\n",
    "le_enthnicity = LabelEncoder()\n",
    "df_6hr['ethnicity'] = le_enthnicity.fit_transform(df_6hr.ethnicity)\n",
    "le_admission_type = LabelEncoder()\n",
    "df_6hr['admission_type'] = le_admission_type.fit_transform(df_6hr.admission_type)\n",
    "\n",
    "# train-test split (note that we should use the same split using icustay_id as in Part 1)\n",
    "df_agg = df_6hr[['icustay_id'] + categorical_features + aggregated_features]\n",
    "df_agg_train = df_agg[df_agg.icustay_id.isin(id_train)].sort_values(by=['icustay_id'])\n",
    "df_agg_val = df_agg[df_agg.icustay_id.isin(id_val)].sort_values(by=['icustay_id'])\n",
    "\n",
    "# merge aggregated/static features and the pred proba of time series features resulted from LSTM\n",
    "data_train = df_ts_train.merge(df_agg_train, left_on='icustay_id', right_on='icustay_id', how='inner')\n",
    "data_val = df_ts_val.merge(df_agg_val, left_on='icustay_id', right_on='icustay_id', how='inner')\n",
    "\n",
    "# train random forest on all features\n",
    "y_train = data_train.hospital_expire_flag\n",
    "X_train = data_train.drop(columns=['icustay_id','hospital_expire_flag'])\n",
    "y_val = data_val.hospital_expire_flag\n",
    "X_val = data_val.drop(columns=['icustay_id','hospital_expire_flag'])\n",
    "                        \n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "y_pred = clf.predict(X_val)\n",
    "y_pred_proba = clf.predict_proba(X_val)\n",
    "\n",
    "y_proba = []\n",
    "for i in range(len(y_pred_proba)):\n",
    "    y_proba.append(y_pred_proba[i][1])\n",
    "    \n",
    "# evaluate the model\n",
    "evaluate(y_val, y_pred, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
